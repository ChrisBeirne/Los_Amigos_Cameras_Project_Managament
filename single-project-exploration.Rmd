---
title: "Wildlife Insights - Single Project"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r wd, include=FALSE}
# DO NOT RUN THIS IF YOU ARE RUNNING LINE BY LINE - ONLY FOR FINAL REPORT (KNIT)
# Set the WD to the project folder (markdowns working directory when you knit the HTML is where the .rmd is located)
require("knitr")
opts_knit$set(root.dir = '../')

```

```{r non-adjustable options, echo=F, include=F}
#Load Packages
list.of.packages <- c("leaflet", "dplyr", "colortools", "kriging", "corrplot", "lubridate", "kableExtra", "rredlist","sf", "usedist", "ggplot2", "ggpubr", "googledrive", "purrr")

# Check you have them and load them
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

lapply(list.of.packages, require, character.only = TRUE)
```


```{r googledrive setup and file import, include=FALSE}
#drive_auth()


# run this line, and enter "Yes". It will open up a browser window, and you'll have to allow access to your Google Drive account
x <- drive_find(n_max = 30)
1
# Create the file
dir.create("data/raw-data")

# you must have stored you wildlife insights data download packet on google drive - link to it with the URL
folder_url <- "https://drive.google.com/drive/folders/1iFtdGqWDDZw_9JhlgFplhE6Hq9TO0zad"
folder <- drive_get(as_id(folder_url))
csv_files <- drive_ls(folder, type = "csv", recursive=F)

# Clear the folder (overwriting old files)
do.call(file.remove, list(list.files("data/raw-data", full.names = TRUE)))

# Downloads all the files into a subfolder
for (i in 1:nrow(csv_files)) {
    drive_download(as_id(csv_files$id[i]), 
                   path = paste("data/raw-data", csv_files$name[i], sep = "/"), 
                   overwrite=T)
}

```


```{r data setup, include=FALSE}
# Load your data 
dat <- read.csv("data/raw-data/images.csv", header=T)
dep <- read.csv("data/raw-data/deployments.csv", header=T)
pro <- read.csv("data/raw-data/projects.csv", header=T, sep=",")
head(dep)
# Timezone  
# They are mainly Reconyx, so use UTC
tz <- "PET"

# Use the strata category to colour plots 
category <- "subproject_name"

# Define a colour from the R options to base the colourscheme
colour <- "lightseagreen"

```


# `r dat$Project.ID[1]` Project

## Important communications

**If there have been any mail communications with the project staff, list them here.**

None to date.

**Points of note**

```{r}

```



### Data checks

```{r}
#head(dep)
####
# DEP isnt in dat
dep[!(dep$Deployment.Location.ID %in% dat$Deployment.Location.ID),]$Deployment.Location.ID

dep$Deployment.Location.ID[dep$Deployment.Location.ID=="C38 Bosporous East"] <- "C38 Bosporous East 288186 5437502"

# C38 Bosporous East


#table(dep$Deployment.Location.ID)

# Dat isnt in dep
unique(dat[!(dat$Deployment.Location.ID %in% dep$Deployment.Location.ID),]$Deployment.Location.ID)


```



## Essential columns check

We have a suite of columns which we have defined as essential. If any columns are absent, they will be returned as a vector.

```{r essential headings, message=F, echo=F}
pd <- c("Project.ID","Project.Name","Objectives","Project.Species","Layout","Layout.Target",
"Project.Bait.Use","Project.Stratification","Project.Stratification.Type","Project.Covid.Design",
"Project.Sensor.Method","Sequence.Definition","Project.Human.Images","Project.Blank.Images",
"Project.Sensor.Cluster","Number.of.Cameras","Country","Project.Admin","Project.Admin.Email",
"Project.Admin.Organization")

dd <- c("Project.ID", "Deployment.Location.ID","Latitude","Longitude","Camera.Deployment.Begin.Date",
"Camera.Deployment.End.Date","Time.Zone","Bait.Type","Feature.Type","Quiet.Period.Setting",
"Camera.Make","Height","Angle")

id <- c("Project.ID","Deployment.Location.ID","Image.ID","Blank","Species","Species.Common.Name",
"Date.Time.Captured","Time.Zone")

```

Missing from:

*Project data*: `r setdiff(pd, colnames(pro))`

*Deployment data*: `r setdiff(dd, colnames(dep))`

*Image data*: `r setdiff(id, colnames(dat))`

If you need to make corrections to column headings do it in the code block below.
```{r, column headings corrections}

colnames(pro)[colnames(pro)=="NumberofCameras"] <- "Number.of.Cameras"
#head(dat)
dat$X <- NULL
#colnames(dat)

```


## Project Information

```{r project data, echo=F, message=F}
t(pro) %>%
  kbl() %>%
  kable_styling(full_width = T) %>%
  column_spec(1, bold = T, border_right = T)

```

### Camera locations

To date there have been camera deployments at `r length(unique(dep$Deployment.Location.ID))` unique locations.

```{r, echo=F, include=F}

# Generate colours to display the catagory levels - R needs them as a factor
dep[,category] <- factor(dep[,category])
col.cat <- wheel(colour, num = length(levels(dep[,category])))
dep$Cols <- col.cat[dep[,category]]
```

```{r map, echo=F}

# Count the number of camera ststions
n.stat <- length(unique(dep$Deployment.Location.ID))

m <- leaflet() %>%
  addProviderTiles(providers$Esri.WorldTopoMap, group="Base") %>%
  addProviderTiles(providers$Esri.WorldImagery, group="Satellite") %>%  # Add satellite data
  
  addCircleMarkers(lng= dep$Longitude, lat= dep$Latitude,
                   color= dep$Cols,
                   popup=paste( dep$Deployment.Location.ID,  dep[,category])) %>%
 addLegend("topleft", colors = col.cat,  labels = levels( dep[,category]),
    title = category,
    labFormat = labelFormat(prefix = "$"),
    opacity = 1
  ) %>%
  # Layers control
  addLayersControl(
    baseGroups = c("Satellite", "Base"),
    options = layersControlOptions(collapsed = FALSE)
  )
m

```

#### Determine distances between all pairs of cameras
```{r, echo =F}
# create spatial file
camera_locs <- dep %>% 
  select(Deployment.Location.ID, Latitude, Longitude) %>% 
  unique() %>% # remove unique rows (in case of multiple deployment)
  st_as_sf(coords = c("Longitude", "Latitude"), crs = "+proj=longlat")

# distance matrix for all cameras
camera_dist <- st_distance(camera_locs) %>% 
  as.dist() %>% 
  usedist::dist_setNames(as.character(camera_locs$Deployment.Location.ID)) %>% 
  as.matrix()

# convert to pairwise list
camera_dist_list <- t(combn(colnames(camera_dist), 2))
camera_dist_list <- data.frame(camera_dist_list, dist = camera_dist[camera_dist_list]) %>% 
  arrange(dist) # sort descending

# Remove stations that have the same name and are <20 apart
camera_dist_list <- camera_dist_list[!(camera_dist_list$X1==camera_dist_list$X2 & camera_dist_list$dist<20),]

# create a list of the closest camera for each station
camera_dist_list <- camera_dist_list %>% 
    group_by(X1) %>% 
    slice(which.min(dist))

```

The average distance to the nearest camera for this project is `r round(mean(camera_dist_list$dist),1)`m, the closest camera is `r round(min(camera_dist_list$dist),1)`m. 

Look at a list of the top 10 closest cameras to see if there is any potential for issues. :

*NOTE* I have remved cameras that have the same name and are < 20 meters apart. 

```{r, echo=F}
colnames(camera_dist_list) <- c("Cam1", "Cam2", "Distance (m)")
camera_dist_list<- camera_dist_list[order(camera_dist_list$'Distance (m)' ),]
camera_dist_list$`Distance (m)` <- round(camera_dist_list$`Distance (m)`,1)

camera_dist_list[1:15,] %>%
  kbl() %>%
  kable_styling(full_width = F) %>%
  column_spec(1:2, bold = T, border_right = T)

```

If we need to group locations due to spatial proximity, use the code chunk below:

```{r}
# Station grouping code
# Not used. 
```



The following code block ensures that all dates are in the appropriate format.

```{r date checks, include =F}
# Prepare dates
dep$Camera.Deployment.Begin.Date <- as.POSIXct(parse_date_time(dep$Camera.Deployment.Begin.Date,c("%Y-%m-%d","%m-%d-%y"), tz ))

dep$Camera.Deployment.End.Date <- as.POSIXct(parse_date_time(dep$Camera.Deployment.End.Date,c("%Y-%m-%d","%m-%d-%y"), tz ))

dep$Days <- as.numeric(round(difftime(dep$Camera.Deployment.End.Date, dep$Camera.Deployment.Begin.Date, units="days"),1))

# Image data
dat$Date.Time.Captured <- parse_date_time(dat$Date.Time.Captured,c("%Y-%m-%d %H:%M:%S %p","%m/%d/%y %H:%M:%S"), tz ) 
```

How many NA's are there. If you have any TRUE values (n > 0) there is an issue:

Deployment data - Begin.Date  = `r nrow(dep[is.na(dep$Camera.Deployment.Begin.Date)==TRUE,])`

Deployment data - End.Date    = `r nrow(dep[is.na(dep$Camera.Deployment.End.Date )==TRUE,])`

Deployment data - Days active = `r nrow(dep[is.na(dep$Days)==TRUE,])`

Image data      - Date.Time.Captured    = `r nrow(dat[is.na(dat$Date.Time.Captured)==TRUE,])`



### Blanks
Are blanks included? If yes are they in logic format?

```{r blank checks, echo=F}
# 1) dat$Blank must be logical
table(dat$Blank)

dat$Blank <- FALSE

# If there are blanks, remove them.
#dat <- dat[dat$Blank==FALSE,]

```

### Species names
Eyeball the list. Does it look sensible? Any repeats?

```{r species names check, echo=F}
# Ensure the species names are consistent - check in the list below
as.data.frame(table(dat$Species))


dat$Species[dat$Species=="Biker"]<- "Homo sapiens"
dat$Species[dat$Species=="Boater"] <- "Homo sapiens"
dat$Species[dat$Species=="Fisherperson"] <- "Homo sapiens"
dat$Species[dat$Species=="Horse Rider"] <- "Homo sapiens"
dat$Species[dat$Species=="Lynx"] <- "Lynx rufus"

dat$Species[dat$Species=="Quad/Vehicle/Motorbike"] <- "Homo sapiens"
dat$Species[dat$Species=="Skier"] <- "Homo sapiens"

# Pull in the old species names
dat$Species.Common.Name <- dat$Species
dat$Species <- NULL
colnames(species.data)[2] <- "Species.Common.Name"

#table(dat$Species.Common.Name)
dat <- left_join(dat, species.data) 
#table(dat$Species)
dat$Species[dat$Species.Common.Name=="Lynx rufus"] <- "Lynx rufus"
dat$Species[dat$Species.Common.Name=="Homo sapiens"] <- "Homo sapiens"

dat[dat$Species=="Red Fox" & is.na(dat$Species)==F,]$Species <- "Vulpes vulpes" 
as.data.frame(table(paste(dat$Species,"  -  ", dat$Species.Common.Name)))

```

#### Are the species names in the taxonomic databases?

Note: The Taxize database checks a bunch of differnt databases (gets round the need for IUCN API key). Other ways of doing this are available! I have added a delay to ensure we dont run over the query limit too. 


```{r species check, echo=F, message=F, warning=F, include=F}
# NOTE YOU NEED AN API KEY FOR IUCN, so I have made a different workflow using taxize

# Get and API key
#rl_use_iucn()
library(taxize)

sp.dat <- data.frame(Species=as.character(unique(dat$Species)), Present=NA)
# Make the order sensible
sp.dat <- sp.dat[order(sp.dat$Species),]
sp.dat$Class <- NA
# Check if it is in a bunch of different taxonomic databases
for(i in 1:nrow(sp.dat))
{
  temp <- gnr_resolve(sp.dat$Species[i])
  
  if(nrow(temp[temp$score>0.9,])>0)
  {
    sp.dat$Present[i] <- TRUE
    temp2 <- get_uid(sp.dat$Species[i], db = "ncbi")
    if(is.na(temp2[1])==F){
    temp2 <- classification(temp2[1], db = "ncbi")
    temp2 <- temp2[[1]]

    sp.dat$Class[i] <- temp2$name[temp2$rank=="class"][1]
    }
  }
  else{sp.dat$Present[i] <- FALSE}
}

row.names(sp.dat) <- 1:nrow(sp.dat)


```

```{r, echo=F}
sp.dat %>%
  kbl() %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T)

```


#### Remove anything that isn't a mammal IDed to a useful level.
Lots going on in here.  Birds, some human stuff, lots of UID's 
```{r remove species without species info}
dat <- dat[dat$Species %in% sp.dat$Species[sp.dat$Class=="Mammalia" & is.na(sp.dat$Class)==F],]

```



### Group size and number of animals
Ensure that any counts are in numeric format.
```{r group sive or number of individuals}
# Ensure Group.Size doesnt have any non-numeric data in! The following should return TRUE
is.numeric(dat$Group.Size)
is.numeric(dat$Number.of.Animals)


summary(dat$Number.of.Animals)
dat[dat$Number.of.Animals>400,]$Number.of.Animals  <- 1
```



### Camera activity through time

The `r n.stat` stations have resulted in a total of `r as.character(round(sum(dep$Days, na.rm=T),0))` camera days (mean = `r round(mean(aggregate(Days~Deployment.Location.ID, data=dep,  FUN=sum, na.rm=T)$Days),1)` days per station; min = `r round(min(aggregate(Days~Deployment.Location.ID, data=dep,  FUN=sum, na.rm=T)$Days),1)`; max = `r round(max(aggregate(Days~Deployment.Location.ID, data=dep,  FUN=sum, na.rm=T)$Days),1)`).The daily break down of camera activity is as follows:

```{r activity, echo=F, fig.height=dep.height}

# Adjust layout
par(mar=c(2,6,1,1))
plot(c(min(dep$Camera.Deployment.Begin.Date, na.rm=T), max(dep$Camera.Deployment.End.Date, na.rm=T)),      c(1,n.stat), las=1, ylab="", xlab="", type="n", yaxt="n", xaxt="n")

axis(2, at= 1:n.stat, labels= unique(dep$Deployment.Location.ID), las=1, cex.axis=0.4)
axis(1, at= seq(min(dep$Camera.Deployment.Begin.Date, na.rm=T), max(dep$Camera.Deployment.End.Date, na.rm=T)-200, length.out=9),
     labels=c(substr(seq(min(dep$Camera.Deployment.Begin.Date, na.rm=T), max(dep$Camera.Deployment.End.Date, na.rm=T)-200, length.out=9),1,7)))
#mtext("Camera Deployment ID", 2, 4)
# Make lines for each of the cameras
for(i in 1:length(unique(dep$Deployment.Location.ID)))
{
  abline(h=i, col=rgb(0,0,0,0.1))
  tmp <- dep[dep$Deployment.Location.ID==unique(dep$Deployment.Location.ID)[i],]
  for(j in 1:nrow(tmp))
    {
      lines(c(tmp$Camera.Deployment.Begin.Date[j],
                       tmp$Camera.Deployment.End.Date[j]),
            c(i,i), lwd=2)
    # Colour lines red if the start time occurs after the end time  
    if(tmp$Days[j]<0)
      {
        lines(c(tmp$Camera.Deployment.Begin.Date[j],
                       tmp$Camera.Deployment.End.Date[j]),
            c(i,i), lwd=3, col="red")
      }
    }
  
}

```

Black lines denote a camera which is active, red lines denote a start date which occurs after an end date,and  white space indicates cameras which are inactive. 

### Deployment details 

**Camera makes:** 

```{r cam makes , echo=F}
tmp <- as.data.frame(table(dep$Camera.Make))
colnames(tmp) <- c("Make", "Frequency")

tmp %>%
  kbl() %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T)

```

**Cameras heights:**

```{r cam heights, echo=F}
dep$Height <- as.numeric(dep$Height)
tmp <- as.data.frame(unclass(summary(dep$Height, na.rm=T)))
colnames(tmp) <- "Height"
if(is.numeric(tmp$Height)==TRUE)
{
tmp$Height <- round(tmp$Height,2)
}
tmp %>%
  kbl() %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T)

```

**Cameras angles:**

```{r cam angles , echo=F}
dep$Angle <- as.numeric(dep$Angle)

tmp <- as.data.frame(table(dep$Angle))
if(nrow(tmp)>1)
{
colnames(tmp) <- c("Angle", "Frequency")

tmp %>%
  kbl() %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T)
} else{ print("Not included.") }
```


### Raw detection summary

There are `r nrow(dat)` image classifications, `r nrow(dat[dat$Blank==FALSE,])` of which are classified as containing a species.

Of the detections which have been identified, there are `r length(levels(factor(dat$Species)))` different catageories. 

```{r captures, echo=F, fig.height=sp.height}
layout(matrix(c(1,1,2), 1, 3, byrow = TRUE))
det.sum.total <- as.data.frame(count(dat[dat$Blank==FALSE & is.na(dat$Species)==FALSE,], Species))
det.sum.total <- det.sum.total[order(det.sum.total$n),]

par(mar=c(5,16,1,1))
barplot(det.sum.total$n, names.arg = paste0(det.sum.total$Species, 
                                           " (n =", det.sum.total$n,")")   , las=1, cex.names=1, xlab="Total detections", horiz=T)
i <-1
for(i in 1:nrow(det.sum.total))
{
  tmp <- subset(dat, Species==det.sum.total$Species[i])
  det.sum.total$Locations[i] <- length(unique(tmp$Deployment.Location.ID))
}
par(mar=c(5,1,1,1))

barplot(det.sum.total$Locations/n.stat, las=1, cex.names=0.7, xlab="Proportion of sites detected", horiz=T, xlim=c(0,1))
abline(v=1, lty=2)

```

### Detection time check

The following plot helps you determine if you have detections occuring outside of the times cameras are active. *Important note* You can still get detections outside of the activity period if you have decided that the field of view was shifted and the data is un-compariable to that which was collected earlier. Plots are broken into managable 20 station chunks.

```{r, include=F}
# Make species colour codes
tmp3 <- data.frame("Species"=unique(dat$Species),"Colour"= wheel("lightseagreen", num = length(unique(dat$Species))))

```


```{r detecion summary, echo=F, message=F, warning=F}
# Make a separate plot for each 20 stations For each 20 stations
# To do this make a plot dattaframe
tmp4 <- data.frame("Deployment.Location.ID"=unique(dep$Deployment.Location.ID), "Plot.grp"=ceiling(1:length(unique(dep$Deployment.Location.ID))/20))

dep <- left_join(dep,tmp4, by = "Deployment.Location.ID")
j <- 1
for(j in 1:length(unique(dep$Plot.grp)))
{
    layout(matrix(c(1,1,1,2), 1, 4, byrow = TRUE))
    par(mar=c(2,6,1,1))
    
    plot(c(min(dep$Camera.Deployment.Begin.Date, na.rm=T), max(dep$Camera.Deployment.End.Date, na.rm=T)),      c(1,length(unique(dep$Deployment.Location.ID[dep$Plot.grp==j]))), las=1, ylab="", xlab="", type="n", yaxt="n")
    
    axis(2, at= 1:length(unique(dep$Deployment.Location.ID[dep$Plot.grp==j])), labels= unique(dep$Deployment.Location.ID[dep$Plot.grp==j]), las=1, cex.axis=1)
    #mtext("Camera Deployment ID", 2, 4)
    # Make lines for each of the cameras
    for(i in 1:length(unique(dep$Deployment.Location.ID[dep$Plot.grp==j])))
    {
      abline(h=i, col=rgb(0,0,0,0.1))
      tmp <- dep[dep$Deployment.Location.ID==unique(dep$Deployment.Location.ID[dep$Plot.grp==j])[i],]
      
      tmp2 <- dat[dat$Deployment.Location.ID==tmp$Deployment.Location.ID[1],]
      tmp2 <- left_join(tmp2, tmp3, by = "Species")
      points(tmp2$Date.Time.Captured, rep(i,nrow(tmp2)), pch="|", col= tmp2$Colour)
    
      for(k in 1:nrow(tmp))
        {
          lines(c(tmp$Camera.Deployment.Begin.Date[k],
                           tmp$Camera.Deployment.End.Date[k]),
                c(i,i), lwd=2)
        }
      }
    par(mar=c(0,0,1,0))
    plot.new()
    legend("topleft", legend=tmp3$Species, fill=tmp3$Colour, xpd=TRUE, cex=1.1 )

}

```

### Human Data
Of the `r nrow(dat)` image classifications, `r nrow(dat[dat$Species=="Homo sapiens",])` are classified as human. 

The human classifcations are broken down into the following classifications:

```{r humans, echo=F, message =F}
table(dat$Species.Common.Name[dat$Species=="Homo sapiens"]) %>%
  kbl() %>%
  kable_styling(full_width = F)
```

## Other data

### Number of animals by species
Was "Number of Animals" included? `r "Number.of.Animals" %in% names(dat)`

```{r Number of Animals, echo=F,fig.height=sp.height}
dat$Species <- as.factor(dat$Species)

if( ("Number.of.Animals" %in% names(dat))==TRUE )
{
  par(mfrow=c(1,1))
  par(mar=c(5,10,1,1))
  plot(jitter(as.numeric(dat$Species))~jitter(dat$Number.of.Animals), xlab="Number of Animals", yaxt="n", las=1, ylab="")
  axis(2, 1:length(unique(dat$Species)), labels=levels(dat$Species), las=2, cex.axis=0.6)
  
}


```

### Group size by species
Was "Group Size" included? `r "Group.Size" %in% names(dat)`

```{r Group Size, echo=F, fig.height=sp.height}
if( ("Group.Size" %in% names(dat))==TRUE)
{
  par(mfrow=c(1,1))
  par(mar=c(5,10,1,1))
  plot(jitter(as.numeric(dat$Species))~jitter(dat$Group.Size), xlab="Group Size", yaxt="n", las=1, ylab="", pch=19, col=rgb(0,0,0,0.2))
  axis(2, 1:length(unique(dat$Species)), labels=levels(dat$Species), las=2, cex.axis=0.6)
  
}

```


## Temporal trends

### Site-level temporal plots

### Summary
Across all sites and species:

```{r creating monthly data, echo=F, eval=T}
##########################
# Capture rates through time
focal.sp <- unique(dat$Species)
focal.sp <- focal.sp[order(focal.sp)]

# We need to know how many detections there are in each month -> create a row lookup
# This is just a list of ever day a camera was active.

tmp <- dep[is.na(dep$Camera.Deployment.End.Date)==F,]
daily.lookup <- list()

for(i in 1:nrow(tmp))
{
  if(as.Date(tmp$Camera.Deployment.Begin.Date[i])!=as.Date(tmp$Camera.Deployment.End.Date[i]))
  {
    daily.lookup[[i]] <- data.frame("Date"=seq(as.Date(tmp$Camera.Deployment.Begin.Date[i])+1, as.Date(tmp$Camera.Deployment.End.Date[i]), by="days"), "Deployment.Location.ID"=tmp$Deployment.Location.ID[i])
  }
}
row.lookup <- do.call(rbind, daily.lookup)

# Now determine capture rates
# Make a data frame by month and year
mon.dat <- unique(substr(dat$Date.Time.Captured, 1,7))
mon.dat <- data.frame("Month"=mon.dat[order(mon.dat)], "Effort"= NA)
mon.dat[as.character(focal.sp)] <- NA
i<-1
# Determine camera effort and total captures
for(i in 1:nrow(mon.dat))
{
  mon.dat$Effort[i] <- nrow(subset(row.lookup, substr(row.lookup$Date,1,7)==mon.dat$Month[i]))
  mon.dat$Total.CR[i] <- (nrow(subset(dat, substr(dat$Date.Time.Captured,1,7)==mon.dat$Month[i]))/mon.dat$Effort[i])*100
}

# Now determine raw detections by species, through time
# This will take a decent amount of time if there are a lot of species.
# Will likely be a better vectorised way of doing this!

for(i in 1:length(focal.sp))
{
  for(j in 1:nrow(mon.dat))
  {
    tmp <- subset(dat, Species==as.character(focal.sp)[i] & substr(dat$Date.Time.Captured,1,7)==mon.dat$Month[j])
    mon.dat[j, as.character(focal.sp[i])] <- (nrow(tmp)/mon.dat$Effort[j])*100
  }
}

mon.dat$timestamp <- strptime(paste0(as.character(mon.dat$Month),"-15"), "%Y-%m-%d")
# Remove rows without effort
mon.dat <- mon.dat[mon.dat$Effort>0,]
```

Are there any infinite detection rates = `r nrow(mon.dat[is.infinite(mon.dat$Total.CR)==T,])>0`

The following plot shows the temporal coverage and detection rates.

```{r overall CR, echo=F, fig.height=4, eval=T}
par(mar=c(5,4,1,1))
par(mfrow=c(1,2))

# Camera effort
plot(mon.dat$timestamp, mon.dat$Effort, ylab="Total monthly effort (camera days)", xlab="Date", type="l", las=1)
points(mon.dat$timestamp, mon.dat$Effort, pch=19, col=rgb(0,0,0,0.4))

# Overall capture rate
plot(mon.dat$timestamp, mon.dat$Total.CR, ylab="Monthly total captrue rate per 100 days", xlab="Date", type="l", las=1, ylim=c(0, max(mon.dat$Total.CR)))
points(mon.dat$timestamp, mon.dat$Total.CR, pch=19, col=rgb(0,0,0,0.4))

```

### Species-specific temporal trends
Species level variation in monthly capture rates for all species are as follows:

```{r species specific temporal trends, echo=F, eval=T}
par(mfrow=c(2,3))
for(i in 1:length(focal.sp))
{
  plot(mon.dat$timestamp, mon.dat[,as.character(focal.sp)[i]], ylab="Capture Rate per 100 days", xlab="", type="l", las=1, main=focal.sp[i])
  points(mon.dat$timestamp, mon.dat[,as.character(focal.sp)[i]], pch=19, col=rgb(0,0,0,0.4))
}

```


# Add additional info to the project data
We are adding some summary data here to make project comparisons easier.

```{r Update project data, echo=F, eval=T}
pro$nCaptures            <- nrow(dat)
pro$nSpecies             <- length(unique(as.character(dat$Species)))
pro$nYears               <- length(unique(substr(dat$Date.Time.Captured,1,4)))
pro$nHumans              <- nrow(dat[dat$Species=="Homo sapiens",])
pro$typesHuman           <- length(unique(dat$Species.Common.Name[dat$Species=="Homo sapiens"]))
pro$nDeploymentLocations <- length(unique(as.character(dep$Deployment.Location.ID)))
pro$nCamDays             <- sum(dep$Days)
pro$camSpacingAvg        <- round(mean(camera_dist_list$`Distance (m)`),1)
pro$camSpacingMin        <- round(min(camera_dist_list$`Distance (m)`),1)
pro$avgLatitude          <- mean(dep$Latitude)
pro$avgLongitude         <- mean(dep$Longitude)
pro$startDate            <- min(dep$Camera.Deployment.Begin.Date)
pro$endDate              <- max(dep$Camera.Deployment.Begin.Date)

t(pro[, c("nCaptures", "nSpecies", "nYears", "nHumans",
"typesHuman", "nDeploymentLocations", "nCamDays",
"camSpacingAvg", "camSpacingMin","avgLatitude", "avgLongitude",
"startDate", "endDate")]) %>%
  kbl() %>%
  kable_styling(full_width = T) %>%
  column_spec(1, bold = T, border_right = T)

```
# Create independent data
Note: This also removes data which falls outside of camera activity periods. 

```{r, echo=F, warning=F, message=F}

#independence threshold
ind_thresh<-30

tmp_dat <- dat

  # Remove observations without animals detected
  tmp_dat <- tmp_dat[tmp_dat$Blank%in%c("No","NO","FALSE"),]
  tmp_dat$Species <- as.character(tmp_dat$Species)
  tmp_dat$Deployment.Location.ID <- as.character(tmp_dat$Deployment.Location.ID)
  
  # Order the datframe by project, Site, date
  tmp_dat <- tmp_dat[order(tmp_dat$Project.ID,tmp_dat$Deployment.Location.ID, tmp_dat$Date.Time.Captured),]
  
  tmp_dat <- tmp_dat %>% 
    #filter(species == i) %>%
    arrange(Project.ID,Deployment.Location.ID) %>% 
    group_by(Deployment.Location.ID, Species) %>% 
    mutate(duration = int_length(Date.Time.Captured %--% lag(Date.Time.Captured)))
  
  # loop that assign group ID   
  tmp_dat$Event.ID <- 9999
  mins <- ind_thresh
  seq <- as.numeric(paste0(nrow(tmp_dat),0))
  seq <- round(seq,-(nchar(seq)))
  for (i in 2:nrow(tmp_dat)) {
    tmp_dat$Event.ID[i-1]  <- paste0("E",format(seq, scientific = F))
    if(is.na(tmp_dat$duration[i]) | abs(tmp_dat$duration[i]) > (mins * 60)){
      seq <- seq + 1 
    }
  }
  
  # Update the information for the last row
  # group ID  for the last row
  if(tmp_dat$duration[nrow(tmp_dat)] < (mins * 60)| 
     is.na(tmp_dat$duration[nrow(tmp_dat)])){
    tmp_dat$Event.ID[nrow(tmp_dat)] <- tmp_dat$Event.ID[nrow(tmp_dat)-1] 
  } else{
    tmp_dat$Event.ID[nrow(tmp_dat)] <- paste0("E",format(seq+1, scientific = F)) 
  }
  
 
  # Subset to independent data at the defined interval
  img.data.ind <- tmp_dat[!duplicated(tmp_dat$Event.ID),]
  img.data.ind <- as.data.frame(img.data.ind)
  img.data.ind$Species <-as.factor(img.data.ind$Species)

  # Remove data that doesnt fall within the activity windows of cameras
  img.data.ind <- img.data.ind[paste(substr(img.data.ind$Date.Time.Captured,1,10), img.data.ind$Deployment.Location.ID) %in% paste(row.lookup$Date, row.lookup$Deployment.Location.ID),]
  dat <- dat[paste(substr(dat$Date.Time.Captured,1,10), dat$Deployment.Location.ID) %in% paste(row.lookup$Date, row.lookup$Deployment.Location.ID),]
  

```
Done. Creating independent data reduced the data frame from `r nrow(dat)` raw observations to `r nrow(img.data.ind)` independent observations. 

```{r, echo=F, warning=F, message=F}
library(ggplot2)
library(ggpubr)

if(pro$nHumans>0)
{

Detections<-data.frame()

#subset to species-specific data (main focus is humans and is thus named)
ind.data_hosa<-img.data.ind[img.data.ind$Species=="Homo sapiens",]

#daily detections - count the number of human detections per day
tmp <-ind.data_hosa%>%
    group_by(Date=as.Date(Date.Time.Captured))%>%
    dplyr::summarise(Date=as.Date(Date.Time.Captured),Dets=n())

    tmp<-tmp[!is.na(tmp$Date),]
    
    day <- tmp[!duplicated(tmp),]
    
#standardize by camera operation
dailyOp<-data.frame()

#get the deployment data for that project
dep_tmp<-dep

#create a camera operation table for that project
camOp_tmp<-matrix(0,nrow=length(unique(dep_tmp$Deployment.Location.ID)),ncol=length(seq.Date(min(as.Date(dep_tmp$Camera.Deployment.Begin.Date)),max(as.Date(dep_tmp$Camera.Deployment.End.Date)),by="day")))

colnames(camOp_tmp)<-as.character(seq.Date(min(as.Date(dep_tmp$Camera.Deployment.Begin.Date)),max(as.Date(dep_tmp$Camera.Deployment.End.Date)),by="day"))

rownames(camOp_tmp)<-unique(dep_tmp$Deployment.Location.ID)

for(d in 1:nrow(dep_tmp)){ #for every deployment period
  theSite<-which(rownames(camOp_tmp)==dep_tmp$Deployment.Location.ID[d])
  theCols<-which(colnames(camOp_tmp)%in%as.character(seq.Date(as.Date(dep_tmp$Camera.Deployment.Begin.Date[d]),
                                                              as.Date(dep_tmp$Camera.Deployment.End.Date[d]),by="day")))
  camOp_tmp[theSite,theCols]<-camOp_tmp[theSite,theCols]+1
}

#add the number of camop days and unique cameras operating per week for that project
dailyOp_tmp<-data.frame(Date=attributes(colSums(camOp_tmp))$names,
                         Cams=NA)

DaysWhichCam<-list()
c<- 1
for(c in 1:nrow(dailyOp_tmp)){
  #cams that operated that day
  dailyOp_tmp$Cams[c] <- length(names(which(camOp_tmp[,which(colnames(camOp_tmp)==dailyOp_tmp$Date[c])]>0))) 
}


dailyOp<-dailyOp_tmp
head(dailyOp)

dailyOp<-dailyOp[!is.na(dailyOp$Date),]
dailyOp$Date <- as.Date(dailyOp$Date)
tmp<-left_join(dailyOp,day, by=c("Date"))

tmp$Dets[is.na(tmp$Dets)==T] <- 0
tmp$week <- paste0(substr(tmp$Date,1,4),"-", week(tmp$Date))

Detections<-tmp


p1 <- ggplot(data = Detections, aes(x =Date , y = Dets/Cams))+
geom_bar(stat = "identity")+
geom_rug(sides="b")+
geom_vline(xintercept =as.Date("2020-03-01"), lty=2, col="red") +
labs(title= "Daily Human detections",x="Date",y="Average humans per day")+
theme(panel.background = element_blank(),
axis.line = element_line(colour = "black"),
plot.title = element_text(size=14, hjust = 0.5),
axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_date(limits = c(as.Date(paste0(substr(min(Detections$Date),1,8),"01")), as.Date(max(Detections$Date))), 
               breaks = seq(as.Date(paste0(substr(min(Detections$Date),1,8),"01")), as.Date(max(Detections$Date)), "quarter"),
               date_labels = "%Y-%m-%d", expand=c(0,30)) 
  


# 
p2 <- ggplot(data=Detections, aes(x=Date, y=Cams)) +
        geom_line() +
  geom_vline(xintercept =as.Date("2020-03-01"), lty=2, col="red") +
theme(panel.background = element_blank(),axis.line = element_line(colour = "black"),
plot.title = element_text(size=14, hjust = 0.5),
axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_date(limits = c(as.Date(paste0(substr(min(Detections$Date),1,8),"01")), as.Date(max(Detections$Date))), 
               breaks = seq(as.Date(paste0(substr(min(Detections$Date),1,8),"01")), as.Date(max(Detections$Date)), "quarter"),
               date_labels = "%Y-%m-%d", expand=c(0,30))


} 

```

# Human dynamics through time
The following plot shows the average human capture rate across all of the cameras in the project. The dashed red line is the 1st of March 2020, a rough placeholder for global lockdowns. The x-axis labels are quarterly (every three months).

```{r, echo=F, warning=F, message=F, fig.height=8}
if(pro$nHumans[1]>0) {
ggpubr::ggarrange(p1,p2, nrow=2, heights=c(4,2))
} else {print("Not possible - no human data")}
```


# Upload cleaned, checked data to Google drive
Issues to be resolved, not yet done. 
```{r data upload, echo=F}
# # # Write cleaned data to clean-data folder
write.csv(dat, paste0("data/clean-data/Image_data_", pro$Project.ID[1], ".csv"), row.names=F)
write.csv(dep, paste0("data/clean-data/Deployment_data_", pro$Project.ID[1], ".csv"), row.names=F)
write.csv(pro[1,], paste0("data/clean-data/Project_data_", pro$Project.ID[1], ".csv"), row.names=F)
write.csv(img.data.ind,paste0("data/clean-data/Independent_Image_data_",img.data.ind$Project.ID[1],"_",ind_thresh,"min_threshold.csv"), row.names= F)


library(googledrive)
library(purrr)

# Get the id for the clean data folder
folder_url <- "https://drive.google.com/drive/folders/1nWw0SPMaqgifCs6AGpGmHa1-wQDtAq_L"

drive_upload(
  paste0("data/clean-data/Image_data_", pro$Project.ID[1], ".csv"),
  as_id(folder_url), overwrite=T
)

drive_upload(
  paste0("data/clean-data/Independent_Image_data_", pro$Project.ID[1], "_",ind_thresh,"min_threshold.csv"),
  as_id(folder_url), overwrite=T
)

drive_upload(
  paste0("data/clean-data/Deployment_data_", pro$Project.ID[1], ".csv"),
  as_id(folder_url), overwrite=T
)

drive_upload(
  paste0("data/clean-data/Project_data_", pro$Project.ID[1], ".csv"),
  as_id(folder_url), overwrite=T
)

```

